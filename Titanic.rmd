---
title: "Titanic"
author: "Niket"
output: html_document
---

***

Kaggle - Titanic Dataset With R

***
```{r}
train <- read.csv("train.csv", header = T) # import train.csv
test <- read.csv("test.csv", header = T) # import test.csv
```


```{r}
str(train) # str
```  


```{r}
table(train$Survived) # table of survived people, 0 = Died, 1 = Survived
```


```{r}
prop.table(table(train$Survived))
# Most people died in train set, so it should be same in the test set too
```


```{r}
test$Survived <- rep(0, 418) # Create a new column survived in test.csv and fill it with 0(Dead) 418 times
```


```{r}
submit <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived) # Store PassengerId and Survived into submit data frame.
```


```{r}
write.csv(submit, file = "died.csv", row.names = F) # Create a csv file with submit, this file contains PassengerId and Survival.
```


62% of our predictions are correct.


***
***

```{r}
# “Women and children ” were saved mostly at this incident. So we will look at them.
```


```{r}
summary(train$Sex)
# majority were male.
```


```{r}
prop.table(table(train$Sex, train$Survived)) # This dosent gives the proper proportion.
prop.table(table(train$Sex, train$Survived),1) # This considers total proportion by rows.
# We can see that 81% of the male died, but only 25% of the females died.
```


```{r}
test$Survived <- 0 # Instead of repeating 0 for all values like before, we assign 0 to whole column.
test$Survived[test$Sex == 'female'] <- 1 # We here state that every women survived.
```


```{r}
submit <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived) # Store PassengerId and Survived into submit data frame.
write.csv(submit, file = "died.csv", row.names = F) # Upadted the previous result.
```


76.555% of our predictions are correct.


***
***

```{r}
train$Child <- 0 # Created a new variable for Child.
train$Child[train$Age < 18] <- 1 # To show whether the passenger is below 18 years.
```


```{r}
aggregate(Survived ~ Child + Sex, data = train, FUN = sum)
# With sum function we get only the number of survivors, but we need total number of people in each subset.
```


```{r} 
aggregate(Survived ~ Child + Sex, data = train, FUN = length) # This fun= length gives the number of people in each subset.
```


```{r}
aggregate(Survived ~ Child + Sex, data = train, FUN = function(x) {sum(x)/length(x)})
# This gives us the proportion by total survived/ total.
# We see that if passengers were female they survived, so passenger age dosen't matter.
```


```{r}
# Fare is a continuous variable,bin the fares into less than $10, between $10 and $20, $20 to $30 and more than $30 and store it to a new variable
train$Fare2 <- '30+'
train$Fare2[train$Fare < 30 & train$Fare >= 20] <- '20-30'
train$Fare2[train$Fare < 20 & train$Fare >=10] <- '10-20'
train$Fare2[train$Fare < 10] <- '10'
```


```{r}
aggregate(Survived ~ Fare2 + Pclass + Sex, data = train, FUN =  function(x) {sum(x)/length(x)}) # check survived with Fare2 and Passenger class and Sex.
# Again male didn't do well regardless of class or fare.
# Also females in Pclass 3 didn't do well.
# Also female in Pclass 3 with 30+ fare might have died as their cabin were located close to iceberg.
```


```{r}
test$Survived <- 0
test$Survived[test$Sex == 'female'] <- 1
test$Survived[test$Sex == 'female' & test$Pclass == 3 & test$Fare >= 20] <- 0
```


```{r}
submit <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived) # Store PassengerId and Survived into submit data frame.
write.csv(submit, file = "died.csv", row.names = F) # Upadted the previous result.
```


77.990% of our predictions are correct.


***
***

```{r}
library(rpart) #rpart for “Recursive Partitioning and Regression Trees” and uses the CART decision tree algorithm.
```


```{r}
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data = train, method = "class") # If you wanted to predict a continuous variable, such as age, you may use method = "anova". This would generate decimal quantities for you. But here, we just want a one or a zero, so method= "class".
```


```{r}
# Examine fit
plot(fit)
text(fit)
```


```{r}
# For better insights from above plot we get these packages.
library(rattle)
library(rpart.plot)
library(RColorBrewer)
```


```{r}
fancyRpartPlot(fit) # This gives better plot
```


```{r}
Prediction <- predict(fit, test, type = "class") # rpart’s predict function, function to model fit object, which contains all of the decisions we see above, class method (for ones and zeros output) .
```


```{r}
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction) # Store PassengerId and Survived into submit data frame.
write.csv(submit, file = "died.csv", row.names = F) # Upadted the previous result.
```


78.469% of our predictions are correct.


***

```{r}
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data = train, method = "class", control = rpart.control(minsplit = 2, cp = 0))  # cp parameter is the metric that stops splits that aren’t deemed important enough, minsplit which governs how many passengers must sit in a bucket before even looking for a split. Max both out and reduce cp to zero and minsplit to 2.
```


```{r}
fancyRpartPlot(fit)
```


74.163% of our predictions are correct.


```{r}
# Last model did better than this.
# ---------Overfitting
```

***
***

```{r}
# we create new data frame combi so that we can work on test and train set together, but first we need to have same number of columns in both. we use rbind to merge them.
test$Survived <- NA
test$Child <- NA
test$Fare2 <- NA
combi <- rbind(train, test)
```


```{r}
# let us see that can we use some information from the Name column to our use.
train$Name[1]
# we see that starting has a title Mr. , this can be used for our prediction, in dataset we see more titles including Miss, Mrs, Master, Countess..
```


```{r}
# we see that Name variable has factor data type, but we need it as a string data type, so we change it.
combi$Name <- as.character(combi$Name)
combi$Name[1]
# we have changed the data type to string, no more levels.
```


```{r}
strsplit(combi$Name[1], split = '[,.]')
strsplit(combi$Name[1], split = '[,.]')[[1]]
strsplit(combi$Name[1], split = '[,.]')[[1]][2]
# So we are able to extract only title Mr from whole string.
```


```{r}
# combi$Title <- strsplit(combi$Name, split='[,.]')[[1]][2] # This dosen't work as it takes all titles as Mr.
```



```{r}
combi$Title <- sapply(combi$Name, FUN = function(x) {strsplit(x, '[,.]')[[1]][2]})
# This splits and stores the titles in the Title data frame.
```


```{r}
combi$Title <- sub(' ', '', combi$Title) # As we were seeing a space before the titles we can substitute space with no space.
```


```{r}
table(combi$Title) # This prints the table for title.
```


```{r}
# combining few titles as they are not that relevant.
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
combi$Title <- factor(combi$Title) # convert title to factor as we now have cateogaries.
```


```{r}
combi$FamilySize <- combi$SibSp + combi$Parch + 1 # add the number of siblings, spouses, parents and children the passenger had with them, and plus one for their own existence  and store it to FamilySize.
```


```{r}
combi$Surname <- sapply(combi$Name, FUN = function(x) {strsplit(x, '[,.]')[[1]][1]}) # extract passenger surname from set.
```


```{r}
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="") # combine familysize and surname
```


```{r}
combi$FamilyID[combi$FamilySize <= 2] <- "Small" # families with 2 or less members
```


```{r}
table(combi$FamilyID)
# we still see families with 1 or 2 people.
```


```{r}
famIDs <- data.frame(table(combi$FamilyID))
```


```{r}
famIDs <- famIDs[famIDs$Freq <= 2,] # only store famIDs with 2 or less.
```


```{r}
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small' # overwrite small to famIDs with 1 or 2 members 
combi$FamilyID <- factor(combi$FamilyID)
```


```{r}
# now we split combi back to test and train
train <- combi[1:891,]
test <- combi[892:1309,]
```


```{r}
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID, data = train, method = "class")
```


```{r}
fancyRpartPlot(fit)
```


```{r}
Prediction <- predict(fit, test, type = "class")
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "died.csv", row.names = FALSE)
```


```{r}
# This improves our prediction.
```


79.426% of our predictions are correct.


***
***


```{r}
summary(combi$Age) # Look for NA values in Age.
# 263 values out of 1309 are missing.
```

```{r}
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + FamilySize, data = combi[!is.na(combi$Age),], method = "anova") 

# !is.na() subsets on whether a value is missing or not, method = "anova" version of our decision tree, as we are not trying to predict a category any more, but a continuous variable.

combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
```


```{r}
# lets look for any other problem in our dataset
summary(combi)
# There are several NA's and blank values.
```


```{r}
#lets have a look at embark
summary(combi$Embarked)
# it has a blank for two passengers.
```


```{r}
# to find out who are the blank values
which(combi$Embarked == '')
```


```{r}
# replace them and encode as factor. 
combi$Embarked[c(62,830)] = "S" # S had maximum embarkments so opted S.
combi$Embarked <- factor(combi$Embarked)
```


```{r}
# looking at fare
summary(combi$Fare)
# 1 NA .
```


```{r}
which(is.na(combi$Fare))
# 1044 had NA, so replace it with median value.
combi$Fare[1044] <- median(combi$Fare, na.rm = TRUE)
```


```{r}
# FamilyID has lot of levels, whereas random forest only takes 32 levels max, so we decrease levels
combi$FamilyID2 <- combi$FamilyID
combi$FamilyID2 <- as.character(combi$FamilyID2)
combi$FamilyID2[combi$FamilySize <= 3] <- 'Small'  # Small family from 2 to 3 people
combi$FamilyID2 <- factor(combi$FamilyID2)
# we are down to 22 levels.
```


```{r}
# now we need Random Forest package.
# install.packages('randomForest')
library(randomForest)
```


```{r}
set.seed(415) # the process has the two sources of randomness, it is good to set random seed in R before we begin. This makes results reproducible next time we load the code up, otherwise we can get different classifications for each run.
```


```{r}
# store combi variables in test and train set.
train <- combi[1:891,]
test <- combi[892:1309,]
```


```{r}
# now we have to run our model.
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID2, data = train, importance=TRUE, ntree=2000)
```


```{r}
# look at important variables
varImpPlot(fit)
```


```{r}
Prediction <- predict(fit, test)
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "randomforest.csv", row.names = FALSE) # store PassengerID and survived in randomforest.csv
```


```{r}
 # This results in decreased correct predictions as per Kaggle.
```


77.512% of our predictions are correct.


***

```{r}
# so we try to improve our result with party package
# install.packages('party')
library(party)
```


```{r}
set.seed(415)

fit <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID, data = train, controls = cforest_unbiased(ntree = 2000, mtry = 3)) # Conditional inference trees are able to handle factors with more levels than Random Forests can.
```


```{r}
Prediction <- predict(fit, test, OOB=TRUE, type = "response")
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "crandomforest.csv", row.names = FALSE) # store PassengerID and survived in crandomforest.csv
```


```{r}
# we get best predictions now. this can still be improved.
```


81.340% of our predictions are correct.